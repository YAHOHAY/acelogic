import os
from typing import TypedDict

from dotenv import load_dotenv
from langchain_groq import ChatGroq
from langgraph.checkpoint.memory import MemorySaver
from ace_logic.ai_agent.promots import PokerDecision, build_action_prompt, build_strategy_prompt

# ==========================================
# 0. åˆå§‹åŒ–å¤§æ¨¡åž‹ (è¯·å¡«å…¥ä½ çš„çœŸå®ž Key)
# ==========================================
# 1. è‡ªåŠ¨å¯»æ‰¾å¹¶åŠ è½½é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ .env æ–‡ä»¶
load_dotenv()

# 2. ä»Žç³»ç»ŸçŽ¯å¢ƒå˜é‡ä¸­å®‰å…¨åœ°æŠŠ Key æå–å‡ºæ¥
GROQ_KEY = os.getenv("GROQ_API_KEY")
llm = ChatGroq(model="llama-3.3-70b-versatile", temperature=0.7)
structured_llm = llm.with_structured_output(PokerDecision)


# ==========================================
# 1. è„‘éƒ¨è‰ç¨¿æœ¬çŠ¶æ€å®šä¹‰
# ==========================================
class AgentThinkingState(TypedDict):
    """AI æ€è€ƒæ—¶çš„è„‘éƒ¨è‰ç¨¿æœ¬ï¼Œç»å¯¹ä¸ä¼šæ±¡æŸ“å¼•æ“Žçš„ TableState"""
    table_state: dict
    player_name: str
    call_amount: int
    inner_monologue: str
    final_action: str
    final_amount: int


def human_action_node(state: AgentThinkingState):
    """äººç±»åŠ¨ä½œèŠ‚ç‚¹ï¼ˆä¼‘çœ èˆ±ï¼‰"""
    print(f"[ðŸ‘¤ äººç±»èŠ‚ç‚¹] æˆåŠŸå”¤é†’ï¼æå–åˆ°äººç±»çŽ©å®¶çš„æ“ä½œ: {state.get('final_action')} {state.get('final_amount')}")
    # åªéœ€è¦è¿”å›žä¸€ä¸ªç©ºå­—å…¸ï¼Œå‘Šè¯‰åº•å±‚æ¡†æž¶ï¼šâ€œæˆ‘ä»€ä¹ˆéƒ½ä¸ä¿®æ”¹ï¼Œç›´æŽ¥æ”¾è¡Œâ€
    return {}


def route_player_type(state: AgentThinkingState) -> str:
    """æ¡ä»¶è£åˆ¤ï¼šå†³å®šä¸‹ä¸€æ­¥åŽ»å“ªä¸ªèŠ‚ç‚¹"""
    player_name = state["player_name"]

    # æˆ‘ä»¬åˆ¶å®šä¸€ä¸ªç®€å•çš„ç‰©ç†è§„åˆ™ï¼šåå­—å« "AHA" æˆ–è€…å¸¦æœ‰ "Human" å­—ç¬¦ä¸²çš„å°±æ˜¯çœŸå®žäººç±»
    if player_name == "AHA" or "Human" in player_name:
        return "human_action_node"  # å¼•å¯¼å‘äººç±»èŠ‚ç‚¹
    else:
        return "perception"  # å¼•å¯¼å‘ AI æ€è€ƒèŠ‚ç‚¹
# ==========================================
# 2. å…·ä½“æ‰§è¡ŒèŠ‚ç‚¹ (Nodes)
# ==========================================
def perception_node(state: AgentThinkingState):
    """ðŸ‘ï¸ èŠ‚ç‚¹ 1ï¼šæ„ŸçŸ¥ä¸Žè®¡ç®—åŽ‹åŠ›"""
    p_name = state["player_name"]
    t_state = state["table_state"]
    stack = state["table_state"]["player_stacks"][p_name]

    current_max = t_state["current_max_bet"]
    my_bet = t_state["player_current_bets"][p_name]
    call_amount = current_max - my_bet

    print(f"\n[ðŸ§  {p_name} çš„å¤§è„‘ - èŠ‚ç‚¹1: æ„ŸçŸ¥] é¢ä¸´ä¸‹æ³¨åŽ‹åŠ›: {call_amount},è¿˜å‰©å¤šå°‘{stack}ç­¹ç ")
    return {"call_amount": call_amount}


def strategy_node(state: AgentThinkingState):
    """ðŸ¤” èŠ‚ç‚¹ 2ï¼šæˆ˜ç•¥åˆ†æž (ç”Ÿæˆå†…å¿ƒç‹¬ç™½)"""
    p_name = state["player_name"]
    t_state = state["table_state"]
    persona = t_state["personas"].get(p_name, "æ ‡å‡†")

    prompt = build_strategy_prompt(p_name, persona, t_state, state["call_amount"])

    # è‡ªç”±è¾“å‡ºä¸€æ®µæ–‡æœ¬ä½œä¸ºâ€œå†…å¿ƒç‹¬ç™½â€
    response = llm.invoke(prompt)
    monologue = response.content

    print(f"[ðŸ§  {p_name} çš„å¤§è„‘ - èŠ‚ç‚¹2: æˆ˜ç•¥] å†…å¿ƒç‹¬ç™½: {monologue}")
    return {"inner_monologue": monologue}


def action_node(state: AgentThinkingState):
    """ðŸ”¨ èŠ‚ç‚¹ 3ï¼šæœ€ç»ˆå†³ç­– (è¾“å‡ºä¸¥æ ¼ JSON)"""
    p_name = state["player_name"]
    stack = state["table_state"]["player_stacks"][p_name]

    prompt = build_action_prompt(stack, state["inner_monologue"])

    try:
        decision = structured_llm.invoke(prompt)
        action = decision.action.upper()
        amount = decision.amount
        print(f"[ðŸ§  {p_name} çš„å¤§è„‘ - èŠ‚ç‚¹3: è¡ŒåŠ¨] å†³å®š: {action} {amount}")
    except Exception as e:
        print(f"[ðŸš¨ AI å´©æºƒä¿æŠ¤] {e}")
        action, amount = ("FOLD" if state["call_amount"] > 0 else "CALL"), 0

    return {"final_action": action, "final_amount": amount}